---
title: Telco customer churn
author:
  - name: Ketao Li
    affiliation: York University
    email:  liketao@yahoo.com
  - name: Kush Halani
    affiliation: York University
    email:  kush.halani@ontariotechu.net
  - name: Josue Romain
    affiliation: York University
    email:  josue.rolland.romain@gmail.com    
  - name: Juan Peña
    affiliation: York University
    email:  jppena62@my.yorku.ca
  - name: Priyanka Patil
    affiliation: York University
    email:  priyanka181994@gmail.com    
abstract: >
  Customer churn is a big challenge for large companies,especially in the highly competitive telecom industry. Due to the effect on the revenues of the companies, they are seeking to find ways to predict potential customer to churn. Therefore, identifying the factors that lead to customer churn is very important to take necessary actions to avoid this churn.Our work is to develop a churn prediction model which helps telecom operators to predict customers who are most likely subject to churn.

output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
---


```{r echo=FALSE, message=FALSE, warnings=FALSE}
# load required libraries
library(ggplot2) # plotting lib
library(gridExtra) # arrange grids
library(dplyr)  # data manipuation
library(mice)  # data imputing
library(corrplot) # correlation matrix plotting/printing
library(pROC) # to measure model performance
library(leaflet) # maps
library(RColorBrewer) # color palettes
library(VIM) # missing value analysis 
library(lattice) # another data plotting library
library(mapview) # saves map objects as file
library(png) # deals with png file measurements
library(knitr) #
library(party) # classification tree
library(klaR) # naive bayes
library(xtable) # tabular data formatting 
library(caret) # predictive models
library(Lahman)
library(correlationfunnel)

# Clean all variables that might be left by other script to avoid collusion
rm(list=ls(all=TRUE))
# set xtable properties for the project
options(xtable.floating = TRUE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)

# pick palettes
mainPalette = brewer.pal(8,"Dark2")

```

```{r global_options, include=FALSE}
# make the images flow nicely
knitr::opts_chunk$set(fig.pos = 'H')
```


## Background

In an industry as competitive as Telecom, leading companies know that the key to success is not just about acquiring new customers, but rather, retaining existing ones. But how do you know which customers are at risk and why, and which negative experiences and interactions have the biggest impact on churn across touchpoints and channels over time.


## Objective

The objective of this research is to find a supervised, binary classification model that would provide accurate forecast of telco customer churn.

# Data Analysis

The data set we are going to use for our research contains  customer’s attributes. There are over 7044 records. It has been sourced from [Kaggle](https://www.kaggle.com/blastchar/telco-customer-churn).


## Data Dictionary



Column Name            | Column Description  
-----------------------| ------------------- 
customerID             | Customer ID 
gender                 | Whether the customer is a male or a female
SeniorCitizen          | Whether the customer is a senior citizen or not (1, 0)
Partner                | Whether the customer has a partner or not (Yes, No)
Dependents             | Whether the customer has dependents or not (Yes, No)
tenure                 | Number of months the customer has stayed with the company
PhoneService           | Whether the customer has a phone service or not (Yes, No)
MultipleLines          | Whether the customer has multiple lines or not (Yes, No, No phone service)
InternetService        | Customer’s internet service provider (DSL, Fiber optic, No)
OnlineSecurity         | Whether the customer has online security or not (Yes, No, No internet service)
OnlineBackup           | Whether the customer has online backup or not (Yes, No, No internet service)
DeviceProtection       | Whether the customer has device protection or not (Yes, No, No internet service)
TechSupport            | Whether the customer has tech support or not (Yes, No, No internet service)
StreamingTV            | Whether the customer has streaming TV or not (Yes, No, No internet service)
StreamingMovies        | Whether the customer has streaming movies or not (Yes, No, No internet service)
Contract               | The contract term of the customer (Month-to-month, One year, Two year)
PaperlessBilling       | Whether the customer has paperless billing or not (Yes, No)
PaymentMethod          | The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))
MonthlyCharges         | The amount charged to the customer monthly
TotalCharges           | The total amount charged to the customer
Churn                  | Whether the customer churned or not (Yes or No)


## Data Exploration

Let's take a close look at the data set.

```{r message=FALSE, warning=FALSE}
customerData = read.csv("../data/WA_Fn-UseC_-Telco-Customer-Churn.csv", 
                        header = TRUE, na.strings = c("NA","","#NA"),sep=",")

```
  

To have the full picture of the data let's print the data summary and sample.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
print(xtable(summary(customerData[,1:8])), include.rownames = FALSE, scalebox=.7)
print(xtable(summary(customerData[,9:16])), include.rownames = FALSE, scalebox=.7)
print(xtable(summary(customerData[,17:21]), caption = "\\tt telco customer churn data Summary", 
             label = "data_head"), include.rownames = FALSE, scalebox=.7)
```
\newpage
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
print(xtable(customerData[1:10,1:12]), scalebox=.6)
print (xtable(customerData[1:10,13:21],
  caption = "\\tt telco customer churn data", label = "data_head"), include.rownames = F,
  scalebox = .6)
```


```{r}


#To see the names of the rows in the dataset
names(customerData)

#Display the dataset structure and sumary
str(customerData)

#Display first rows of the dataset
head(customerData)

#To select just the continuous variables and summarise it
library(dplyr)
continues <- select_if(customerData, is.numeric)
#Sumarize the variables to find NA's and outliers
summary(continues)

#Display the factor columns and summarise it
factorColumns <- select_if(customerData, is.factor)
summary(factorColumns)
```

### Missing Data
   From the above summary, we can observe that there are only 11 TotalCharges NA. Considering the number of missing data is quite small, we can remove them directly. 

### Continuous Variables
For continuous variables, let's check for their distributions.

```{r echo= FALSE, warning = FALSE, message=FALSE}
ggplot(data = customerData, aes(MonthlyCharges, color = Churn))+
  geom_freqpoly(binwidth = 5, size = 1)
```

The number of current customers with MonthlyCharges below $25 is extremly high. For the customers with Monthlycharges greater than $30, 
the distributions are similar between who churned and who did not churn.

```{r echo= FALSE, warning = FALSE, message=FALSE}
ggplot(data = customerData, aes(TotalCharges, color = Churn))+
  geom_freqpoly(binwidth = 200, size = 1)
```

The distribution of TotalCharges is highly positive skew for all customers no matter whether they churned or not. 

```{r echo= FALSE, warning = FALSE, message=FALSE}
ggplot(data = customerData, aes(tenure, colour = Churn))+
  geom_freqpoly(binwidth = 5, size = 1)
```

The distributions for tenure are very different between customers who churned and who didn't churn. For customers who churned, the distribution is positve skew, which means customers who churned are more likely to cancel the service in the first couple of months. For current customers who didn't churn, there are two spikes. The second spike is much more drastic than the first one, which means a large group of current customers have been using the service more than 5 years.
There is no obvious outliers for 3 numeric variables.


### Data correlation and other observations
We plot the relationship between pridictive variable and Churn to identify the possible key variable.

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(gender, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer gender Status", 
       x = "gender", 
       y = "Count")

```



```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(Partner, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer Partner Status", 
       x = "Partner", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(Dependents, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer Dependents Status", 
       x = "Dependents", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(PhoneService, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer PhoneService Status", 
       x = "PhoneService", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(MultipleLines, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer MultipleLines Status", 
       x = "MultipleLines", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(InternetService, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer InternetService Status", 
       x = "InternetService", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(OnlineSecurity, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer OnlineSecurity Status", 
       x = "OnlineSecurity", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(OnlineBackup, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer OnlineBackup Status", 
       x = "OnlineBackup", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(DeviceProtection, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer DeviceProtection Status", 
       x = "DeviceProtection", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(TechSupport, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer TechSupport Status", 
       x = "TechSupport", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(StreamingTV, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer StreamingTV Status", 
       x = "StreamingTV", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(StreamingMovies, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer StreamingMovies Status", 
       x = "StreamingMovies", 
       y = "Count")

```
```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(Contract, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer Contract Status", 
       x = "Contract", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(PaperlessBilling, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer PaperlessBilling Status", 
       x = "PaperlessBilling", 
       y = "Count")

```


```{r test1,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Test1 ", out.width="1.1\\linewidth"}
ggplot(factorColumns, aes(PaymentMethod, fill = Churn)) + 
  geom_bar() +
  labs(title = "Customer PaymentMethod Status", 
       x = "PaymentMethod", 
       y = "Count")

```


```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(customerData, aes(tenure, fill = Churn)) + 
  geom_histogram() +
  labs(title = "Customer Tenure Histogram", 
       x = "tenure", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}

ggplot(customerData, aes(SeniorCitizen, fill = Churn)) + 
  geom_histogram() +
  labs(title = "SeniorCitizen Histogram",
       x = "SeniorCitizen", 
       y = "Count")


```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}

ggplot(customerData, aes(MonthlyCharges, fill = Churn)) + 
  geom_histogram() +
  labs(title = "Monthly Charges Histogram",
       x = "Monthly Charge to Customer", 
       y = "Count")

```

```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(customerData, aes(TotalCharges, fill = Churn)) + 
  geom_histogram() +
  labs(title = "TotalCharges Histogram",
       x = "TotalCharges", 
       y = "Count")

```


General Insights From Initial Data Exploration
These are simple observations made by looking at the above charts.

-Customers with a partner or dependents are much less likely to cancel their service 
-The longer a customer’s tenure, the less likely they are to cancel 
-Customers with fiber optic internet service are especially likely to cancel -Customers on month-to-month contracts are especially likely to cancel 
-Customers who use paperless billing are more likely to cancel 
-Customers who pay by electronic check are more likely to cancel

We guess that Having a partner is highly correlated with having dependents.Plot the correlation between them.
```{r ,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap=" ", out.width="1.1\\linewidth"}
ggplot(customerData, aes(Partner, fill = Dependents )) + 
  geom_bar(position = 'fill') +
  labs(title = "Customer Dependents Status", 
       x = "Does the Customer have a Partner?", 
       y = "Fraction")

```

From the above plot,our guess is verified.
 


Next,we use the other method to visualize the feature-target relationships.

```{r echo=TRUE}

customer_churn_tbl = read.csv("../data/WA_Fn-UseC_-Telco-Customer-Churn.csv" )
data("customer_churn_tbl")


customer_churn_binarized_tbl <- customer_churn_tbl %>%
  dplyr::select(-customerID) %>%
  mutate(TotalCharges = ifelse(is.na(TotalCharges), MonthlyCharges, TotalCharges)) %>%
  binarize(n_bins = 5, thresh_infreq = 0.01, name_infreq = "OTHER", one_hot = TRUE)

customer_churn_corr_tbl <- customer_churn_binarized_tbl %>%
  correlate(Churn__Yes)

customer_churn_corr_tbl

customer_churn_corr_tbl %>%
  plot_correlation_funnel()





```

We can see that the following features are correlated with Churn:

“Month to Month” Contract Type
No Online Security
No Tech Support
Customer tenure less than 6 months
Fiber Optic internet service
Pays with electronic check

We can also see that the following features are correlated with Staying (No Churn):

“Two Year” Contract Type
Customer Purchases Online Security
Customer Purchases Tech Support
Customer tenure greater than 60 months (5 years)
DSL internet service
Pays with automatic credit card

Obviously, variable customeID doesn't have any effect for the pridition.So we remove this feature. 
```{r echo=TRUE}
customerData = customerData %>%filter(complete.cases(.)) 
customerData = subset(customerData,select = -customerID)

```


# Modeling and Evalutation

Finally we have reached the stage where we can start training and evaluating classification models. At this point we have clear understanding of our data. We have gotten rid of the features that did not present much value.

## Feature Selection

Generally speaking feature evaluation methods can be separated into two groups: those that use the model information and those that do not. Clearly at this stage of our research the models are not ready. Thus we will be exploring the methods that do not require model.

Before we proceed any further let's ensure that all categorical values get converted back to the factors. This is useful for dimentiality reduction algorithms and model training.



```{r}
customerData = mutate(customerData,
          gender = as.factor(unclass(gender)),
          Partner = as.factor(unclass(Partner)), 
          Dependents = as.factor(unclass(Dependents)),
          PhoneService = as.factor(unclass(PhoneService)), 
          MultipleLines = as.factor(unclass(MultipleLines)),
          InternetService = as.factor(unclass(InternetService)),
          OnlineSecurity = as.factor(unclass(OnlineSecurity)), 
          OnlineBackup = as.factor(unclass(OnlineBackup)),
          DeviceProtection = as.factor(unclass(DeviceProtection)), 
          TechSupport = as.factor(unclass(TechSupport)),
          StreamingTV = as.factor(unclass(StreamingTV)),
          StreamingMovies = as.factor(unclass(StreamingMovies)), 
          Contract = as.factor(unclass(Contract)),
          PaperlessBilling = as.factor(unclass(PaperlessBilling)), 
          PaymentMethod = as.factor(unclass(PaymentMethod)),          
          Churn = as.factor(unclass(Churn)))
```


It is time to run feature selection algorithm.
```{r}
predictors = subset(customerData,select = -Churn)
label = customerData[,20]

# run the RFE algorithm
rfePrediction = rfe(predictors, label, sizes=c(1:19), 
                    rfeControl = rfeControl(functions=rfFuncs, method="cv", number=3))
print(rfePrediction)
```


```{r plot_feature_selection,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Number of Predictors vs Accuracy", out.width="1.1\\linewidth"}
plot(rfePrediction, type=c("g", "o"))
```


Figure \ref{fig:plot_feature_selection} illustrates that the accuracy practically flattens out when a number of predictors reaches 8. The accuracy improves a bit more when a number of features reaches 8 but the gain is negligible. Here is the list of features ordered by importance. We take first nine for model training.

```{r echo=FALSE}
print(predictors(rfePrediction))
```

```{r include=FALSE}
len = length(predictors(rfePrediction))
selectedPredictors =  predictors(rfePrediction)[1:ifelse(len < 8, len, 8)]
print(selectedPredictors)
# remove useless variables
rm(label,predictors,rfePrediction,len)
```

### Data Upsampling

There is one more step to make before we get to the model training. As shown in Figure \ref{fig:feature_distribution} our data set is unbalanced. This could cause model over-fitting. So let's split the data into the training and testing sets and up-sample the training set.
```{r echo=TRUE}
set.seed(1608)

# keep only the selected features
finalSample = customerData %>% dplyr::select(c(selectedPredictors,"Churn"));

splitIdx = createDataPartition(finalSample$Churn, p=0.7, list = F)  # 70% training data
trainData = finalSample[splitIdx, ]
testData = finalSample[-splitIdx, ]

set.seed(590045)
columns = colnames(trainData)
trainData = upSample(x = trainData[, columns[columns != "Churn"] ], 
      y = trainData$Churn, list = F, yname = "Churn")

rm(splitIdx, columns, finalSample)
print(table(trainData$Churn))
```

As we can see now the training set is balanced.

Thus we have prepared our training and test data sets. We have identified the most important features. We are ready to work on the prediction models.
```{r include=FALSE}
# seed for all models
modelSeed = 4987
# helper to compose training composition
selectedPredictorsPlus = paste(selectedPredictors, collapse = " + ")
```

## Decision Tree Model

Decision Tree algorithm is simple to understand, interpret and visualize. Effort required for data preparation is small 
```{r echo=FALSE}
set.seed(modelSeed)
trainDataCopy = mutate(trainData, Churn = as.factor(ifelse(Churn==1, "no", "yes")))
testDataCopy = mutate(testData, Churn = as.factor(ifelse(Churn==1, "no", "yes")))
ctrl = trainControl(method="cv", number = 5, 
    # Estimate class probabilities
    classProbs = T,
    # Evaluate performance using the following function
    summaryFunction = twoClassSummary)

decisionTreeModel = caret::train(as.formula(paste('Churn ~', selectedPredictorsPlus)), 
   data = trainDataCopy, method = "ctree", metric="ROC", trControl = ctrl)

pred.decisionTreeModel.prob = predict(decisionTreeModel, newdata = testDataCopy, type="prob")
pred.decisionTreeModel.raw = predict(decisionTreeModel, newdata = testDataCopy )

roc.decisionTreeModel = pROC::roc(testDataCopy$Churn, 
                    as.vector(ifelse(pred.decisionTreeModel.prob[,"yes"] >0.5, 1,0)) )
auc.decisionTreeModel = pROC::auc(roc.decisionTreeModel)

decisionTreeModel
```

```{r}
confusionMatrix(data = pred.decisionTreeModel.raw, testDataCopy$Churn)
```
```{r plot_decTree_ROC,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Classification Tree Model AUC and ROC Curve", out.width="1.1\\linewidth"}
plot.roc(roc.decisionTreeModel, print.auc = T, auc.polygon = T, col = mainPalette[1] , print.thres = "best" )
```
```{r include=FALSE}
rm(trainDataCopy,testDataCopy,ctrl)
```


## Random Forest Model

Random Forest is also considered as a very handy and easy to use algorithm, because it’s default hyperparameters often produce a good prediction result. Random Forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
set.seed(modelSeed)
trainDataCopy = mutate(trainData, Churn = as.factor(ifelse(Churn==1, "no", "yes")))
testDataCopy = mutate(testData, Churn = as.factor(ifelse(Churn==1, "no", "yes")))
ctrl = trainControl(method = "cv", number = 3, # it takes forever for 10 - fold 
    # Estimate class probabilities
    classProbs = T,
    # Evaluate performance using the following function
    summaryFunction = twoClassSummary)
ptm_rf <- proc.time()
randomForestModel = caret::train(as.formula(paste('Churn ~', selectedPredictorsPlus)), 
   data = trainDataCopy, method = "rf", metric="ROC", trControl = ctrl)
proc.time() - ptm_rf
pred.randomForestModel.prob = predict(randomForestModel, newdata = testDataCopy, type="prob")
pred.randomForestModel.raw = predict(randomForestModel, newdata = testDataCopy )

roc.randomForestModel = pROC::roc(testDataCopy$Churn,  
                                  as.vector(ifelse(pred.randomForestModel.prob[,"yes"] >0.5, 1,0)) )
auc.randomForestModel = pROC::auc(roc.randomForestModel)
randomForestModel
```

```{r}
confusionMatrix(data = pred.randomForestModel.raw, testDataCopy$Churn)
```

```{r plot_rf_ROC,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Random Forest Model AUC and ROC Curve", out.width="1.1\\linewidth"}
plot.roc(roc.randomForestModel, print.auc = T, auc.polygon = T, col = mainPalette[3] , print.thres = "best" )
```

```{r include=FALSE}
rm(trainDataCopy,testDataCopy,ctrl)
```

## Logistic Regression Model

Logistic regression is an efficient, interpretable and accurate method, which fits quickly with minimal tuning. Logistic regression prediction accuracy will benefit if the data is close to Gaussian distribution. Thus we apply addition transformation to the training data set. 
```{r include=FALSE, message=FALSE, warning=FALSE}
set.seed(modelSeed)


trainDataCopy = subset(trainData)
testDataCopy = subset(testData )

ctrl = trainControl(
  # 5-fold CV
  method="cv", number = 5,  
  savePredictions = T)

logRegModel = caret::train(as.formula(paste('Churn ~', selectedPredictorsPlus)),
        data = trainDataCopy, method="glm", family = binomial(link = "logit"), 
        trControl = ctrl, preProc = c("BoxCox"))

pred.logRegModel.raw = predict(logRegModel, newdata =  testDataCopy)
pred.logRegModel.prob = predict(logRegModel, newdata =  testDataCopy, type = "prob")
roc.logRegModel = pROC::roc(testDataCopy$Churn, as.vector(ifelse(pred.logRegModel.prob[,"1"] >0.5, 1,0)))
auc.logRegModel = pROC::auc(roc.logRegModel)

logRegModel
# save the model. Do it once.
# save(logRegModel, file="../data/logRegModel.Rdata")
```
```{r}
confusionMatrix(data = pred.logRegModel.raw, testDataCopy$Churn)
```

```{r plot_logReg_ROC,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Logistic Regression Model AUC and ROC Curve", out.width="1.1\\linewidth"}
plot.roc(roc.logRegModel, rint.auc = T, auc.polygon = T, col = mainPalette[4] , print.thres = "best" )
```


```{r include=FALSE}
rm(trainDataCopy,testDataCopy,ctrl)
```

## Model Comparison

Now it is time to compare the models side by side and pick a winner.

```{r plot_model_comp, fig.align="center", fig.cap="Model AUC Comparison", message=FALSE, warning=FALSE, echo=FALSE, out.width="1.1\\linewidth"}
modelsFace2Face = data.frame(model=c("logRegModel", "decisionTreeModel",
        "randomForestModel"),
        auc=c(auc.logRegModel, auc.decisionTreeModel, auc.randomForestModel))
modelsFace2Face = modelsFace2Face[order(modelsFace2Face$auc, decreasing = T),]
modelsFace2Face$model = factor(modelsFace2Face$model, levels = modelsFace2Face$model)

ggplot(data = modelsFace2Face, aes(x=model, y=auc)) +
  geom_bar(stat="identity", fill=mainPalette[3], colour=mainPalette[3], alpha = 0.5)

print(modelsFace2Face)
```

#### AUC - ROC perfomance

AUC stands for Area under the ROC Curve and ROC for Receiver operating characteristic curve. This is one of the most important KPIs of the classification algorithms. These two metrics measure how well the models distinguishing between the classes. The higher AUC the better model predicts positive and negative outcome. 

Figures \ref{fig:plot_decTree_ROC},  \ref{fig:plot_rf_ROC}, \ref{fig:plot_logReg_ROC} and accompanying data show that on the test data set all the models demonstrated very close resuts. Random Forest has the highest overall accuracy (76%) but the balanced accuracy is lower (about 72%). 

Logistic regression model scores the best having the highest AUC and all other metrics. It's balanced accuracy is 75%.

#### Model interpretibility

Logistic Regression, Decision Tree are all highly interpreatable models. It is easy to explain to the business what impact each input parameter has. The decision tree could be visualized (provided if it is not too large). 

Random Forest on the other hand is a black-box model, complex algorithm which is difficult to explain in simple terms.



# Model Deployment

The model can demonstrate how various customer elements affect the probability of the churn.This model is helpful for the telco companies to identify the customers who can churn.For these customers,some retain actions should be taken accordingly.
Currently we use the features provided by the dataset.However, in the future there could be new features show up, then we must update our model accordingly. 

We also develop one shiny app.It is simple to understand and deploy. 


# Conclusion

Through exploring customer churn dataset,we selected and tuned a model to predict whether one customer could churn.

We commenced our research analyzing and understanding available data . Then we identified the missing data, its distribution. We continued our research selecting the most impactful data attributes to use as an input for our future model. We apply the feature identification algorithm to do the job.

When the data preparation phase was finished we picked and analysed four different classification models: Decision Tree, Random Forest and Logistic Regression. We conducted comparative analysis of the models, reviewed their strength and weaknesses. We fitted each model using K-fold cross-validation technique. Subsequently we evaluated performance of each model applying them to the test data set and comparing AUC - ROC and balanced accuracy metrics. 

Finally we moved to identifying a winning model. In order to so we reviewed each model from different angles including performance,interpretability and data quality sensitivity and data preparation effort

The winning model scored the highest in the majority of the categories. It was Logistic Regression, which we employed to build a Shiny App Web application.

We consider the project to be a success. 
\newpage

\bibliography{RJreferences}

# Note from the Authors

This file was generated using [_The R Journal_ style article template](https://github.com/rstudio/rticles), additional information on how to prepare articles for submission is here - [Instructions for Authors](https://journal.r-project.org/share/author-guide.pdf). The article itself is an executable R Markdown file that could be [downloaded from Github](https://github.com/ivbsoftware/big-data-final-2/blob/master/docs/R_Journal/big-data-final-2/) with all the necessary artifacts.

